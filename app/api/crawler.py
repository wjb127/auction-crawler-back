from typing import Dict
from fastapi import APIRouter, Depends, BackgroundTasks
from sqlalchemy.ext.asyncio import AsyncSession

from app.database import get_db
from app.crawler import CourtAuctionCrawler
from app.services import KeywordMatcher

router = APIRouter(prefix="/crawler", tags=["crawler"])


@router.post("/run", response_model=Dict)
async def run_crawler(
    background_tasks: BackgroundTasks,
    pages: int = 3,
    db: AsyncSession = Depends(get_db)
):
    """ìˆ˜ë™ í¬ë¡¤ë§ ì‹¤í–‰"""
    
    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ í¬ë¡¤ë§ ì‹¤í–‰
    background_tasks.add_task(perform_crawling, db, pages)
    
    return {
        "message": "í¬ë¡¤ë§ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤",
        "pages": pages,
        "status": "started"
    }


@router.get("/status")
async def get_crawler_status():
    """í¬ë¡¤ëŸ¬ ìƒíƒœ ì¡°íšŒ"""
    return {
        "status": "ready",
        "message": "í¬ë¡¤ëŸ¬ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤",
        "supported_sites": ["ëŒ€ë²•ì› ê²½ë§¤ì •ë³´"]
    }


async def perform_crawling(db: AsyncSession, pages: int = 3):
    """ì‹¤ì œ í¬ë¡¤ë§ ìˆ˜í–‰"""
    try:
        print("ğŸ•·ï¸ í¬ë¡¤ë§ ì‹œì‘...")
        
        # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
        crawler = CourtAuctionCrawler()
        matcher = KeywordMatcher()
        
        # í¬ë¡¤ë§ ì‹¤í–‰
        crawled_items = await crawler.crawl_items(pages)
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ ë° ì•Œë¦¼ ì²˜ë¦¬
        results = await matcher.process_crawled_items(db, crawled_items)
        
        print(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ: {results}")
        
        # í¬ë¡¤ëŸ¬ ì •ë¦¬
        crawler.close()
        
    except Exception as e:
        print(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        raise 